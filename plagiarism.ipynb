{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "امروز به خانه رفتم.\n",
    "در مسیر خانه ناگهان گربه فریاد زد و ترسیدم.\n",
    "وقتی رسیدم باران قطع شده و رنگین کمان زیبایی در آسمان ظاهر شد.\n",
    "با گرفتن یک عکس این لحظه زیبا را ابدی کردم.\n",
    "دست به جیب شده و کلید را برداشتم.\n",
    "متاسفانه ولی کلید نبود.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"\n",
    "امروز به خانه رفتم.\n",
    "در مسیر خانه ناگهان ترسیدم.\n",
    "وقتی رسیدم باران قطع شده و رنگین کمان زیبایی در آسمان ظاهر شد.\n",
    "سعی کردم لحظه را ابدی کنم.\n",
    "نبود کلید متاسفانه ولی.\n",
    "خوشبختانه همسرم در خانه بود.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus = text1 + text2\n",
    "vocabs = sorted(set(text_corpus.split()))\n",
    "vocabs = [vocab.replace('.','') for vocab in vocabs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {u:i for i, u in enumerate(vocabs)}\n",
    "idx2word = np.array(vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_list = []\n",
    "text1_list_word = []\n",
    "for sentent in text1.split('.'):\n",
    "    text_as_int = np.array([word2idx[word] for word in sentent.split()])\n",
    "    text1_list.append(text_as_int)\n",
    "    text1_list_word.append(sentent)\n",
    "text1_list = text1_list[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2_list = []\n",
    "for sentent in text2.split('.'):\n",
    "    text_as_int = np.array([word2idx[word] for word in sentent.split()])\n",
    "    text2_list.append(text_as_int)\n",
    "text2_list = text2_list[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 2,  7, 11, 17]),\n",
       " array([13, 31, 11, 32, 45, 27, 19, 36,  9]),\n",
       " array([37, 16,  5, 28, 24, 36, 18, 43, 21, 13,  0, 25, 23]),\n",
       " array([ 4, 46, 47, 26,  3, 29, 20, 15,  1, 41]),\n",
       " array([14,  7, 10, 24, 36, 42, 15,  6]),\n",
       " array([30, 39, 42, 34])]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 2,  7, 11, 17]),\n",
       " array([13, 31, 11, 32,  9]),\n",
       " array([37, 16,  5, 28, 24, 36, 18, 43, 21, 13,  0, 25, 23]),\n",
       " array([22, 41, 29, 15,  1, 44]),\n",
       " array([34, 42, 30, 39]),\n",
       " array([12, 35, 13, 11,  8])]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_size = len(text1_list)\n",
    "text2_size = len(text2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IntersectionTwoLists(list1, list2): \n",
    "    return set(list1).intersection(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_arr = np.zeros((text1_size, text2_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentent1 in enumerate(text1_list):\n",
    "    for j, sentent2 in enumerate(text2_list):\n",
    "        itersect = IntersectionTwoLists(sentent1, sentent2)\n",
    "        if(len(itersect) != 0):\n",
    "            sim_arr[i][j] = round(len(itersect)/len(set(sentent1)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.25, 0.  , 0.  , 0.  , 0.25],\n",
       "       [0.11, 0.56, 0.22, 0.  , 0.  , 0.22],\n",
       "       [0.  , 0.08, 1.  , 0.  , 0.  , 0.08],\n",
       "       [0.  , 0.  , 0.  , 0.4 , 0.  , 0.  ],\n",
       "       [0.12, 0.  , 0.25, 0.12, 0.12, 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 1.  , 0.  ]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 5, 0], dtype=int64)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_sim = np.argmax(sim_arr, axis=0)\n",
    "most_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between sentent 1 of text1 and sentent 1 of text2 = 1.0% {17, 2, 11, 7}\n",
      "similarity between sentent 1 of text1 and sentent 2 of text2 = 0.25% {11}\n",
      "similarity between sentent 1 of text1 and sentent 3 of text2 = 0%\n",
      "similarity between sentent 1 of text1 and sentent 4 of text2 = 0%\n",
      "similarity between sentent 1 of text1 and sentent 5 of text2 = 0%\n",
      "similarity between sentent 1 of text1 and sentent 6 of text2 = 0.25% {11}\n",
      "similarity between sentent 2 of text1 and sentent 1 of text2 = 0.11% {11}\n",
      "similarity between sentent 2 of text1 and sentent 2 of text2 = 0.56% {32, 9, 11, 13, 31}\n",
      "similarity between sentent 2 of text1 and sentent 3 of text2 = 0.22% {36, 13}\n",
      "similarity between sentent 2 of text1 and sentent 4 of text2 = 0%\n",
      "similarity between sentent 2 of text1 and sentent 5 of text2 = 0%\n",
      "similarity between sentent 2 of text1 and sentent 6 of text2 = 0.22% {11, 13}\n",
      "similarity between sentent 3 of text1 and sentent 1 of text2 = 0%\n",
      "similarity between sentent 3 of text1 and sentent 2 of text2 = 0.08% {13}\n",
      "similarity between sentent 3 of text1 and sentent 3 of text2 = 1.0% {0, 36, 5, 37, 43, 13, 16, 18, 21, 23, 24, 25, 28}\n",
      "similarity between sentent 3 of text1 and sentent 4 of text2 = 0%\n",
      "similarity between sentent 3 of text1 and sentent 5 of text2 = 0%\n",
      "similarity between sentent 3 of text1 and sentent 6 of text2 = 0.08% {13}\n",
      "similarity between sentent 4 of text1 and sentent 1 of text2 = 0%\n",
      "similarity between sentent 4 of text1 and sentent 2 of text2 = 0%\n",
      "similarity between sentent 4 of text1 and sentent 3 of text2 = 0%\n",
      "similarity between sentent 4 of text1 and sentent 4 of text2 = 0.4% {41, 29, 1, 15}\n",
      "similarity between sentent 4 of text1 and sentent 5 of text2 = 0%\n",
      "similarity between sentent 4 of text1 and sentent 6 of text2 = 0%\n",
      "similarity between sentent 5 of text1 and sentent 1 of text2 = 0.12% {7}\n",
      "similarity between sentent 5 of text1 and sentent 2 of text2 = 0%\n",
      "similarity between sentent 5 of text1 and sentent 3 of text2 = 0.25% {24, 36}\n",
      "similarity between sentent 5 of text1 and sentent 4 of text2 = 0.12% {15}\n",
      "similarity between sentent 5 of text1 and sentent 5 of text2 = 0.12% {42}\n",
      "similarity between sentent 5 of text1 and sentent 6 of text2 = 0%\n",
      "similarity between sentent 6 of text1 and sentent 1 of text2 = 0%\n",
      "similarity between sentent 6 of text1 and sentent 2 of text2 = 0%\n",
      "similarity between sentent 6 of text1 and sentent 3 of text2 = 0%\n",
      "similarity between sentent 6 of text1 and sentent 4 of text2 = 0%\n",
      "similarity between sentent 6 of text1 and sentent 5 of text2 = 1.0% {34, 42, 30, 39}\n",
      "similarity between sentent 6 of text1 and sentent 6 of text2 = 0%\n"
     ]
    }
   ],
   "source": [
    "for i, sentent1 in enumerate(text1_list):\n",
    "    sent_orgi_length = len(set(sentent1))\n",
    "    for j, sentent2 in enumerate(text2_list):\n",
    "        itersect = IntersectionTwoLists(sentent1, sentent2)\n",
    "        if(len(itersect) != 0):\n",
    "            sim = len(itersect)/sent_orgi_length\n",
    "            print('similarity between sentent {} of text1 and sentent {} of text2 = {}% {}'.format(i+1 ,j+1 ,round(sim,2) , itersect))\n",
    "        else:\n",
    "            print('similarity between sentent {} of text1 and sentent {} of text2 = {}%'.format(i+1 ,j+1 ,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " میزان شباهت متن دوم به متن اول محاسبه کردیم \n",
    "در این روش متن اول، مرجع بوده و نسبت به آن مقایسه صورت گرفته است"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "متن اول:\n",
      "امروز به خانه رفتم.\n",
      "در مسیر خانه ناگهان گربه فریاد زد و ترسیدم.\n",
      "وقتی رسیدم باران قطع شده و رنگین کمان زیبایی در آسمان ظاهر شد.\n",
      "با گرفتن یک عکس این لحظه زیبا را ابدی کردم.\n",
      "دست به جیب شده و کلید را برداشتم.\n",
      "متاسفانه ولی کلید نبود.\n",
      "\n",
      "متن دوم:\n",
      "امروز به خانه رفتم.\n",
      "در مسیر خانه ناگهان ترسیدم.\n",
      "وقتی رسیدم باران قطع شده و رنگین کمان زیبایی در آسمان ظاهر شد.\n",
      "سعی کردم لحظه را ابدی کنم.\n",
      "نبود کلید متاسفانه ولی.\n",
      "خوشبختانه همسرم در خانه بود.\n",
      "\n",
      "جملات مشابه: \n",
      "امروز به خانه رفتم 1.0\n",
      "در مسیر خانه ناگهان گربه فریاد زد و ترسیدم 0.56\n",
      "وقتی رسیدم باران قطع شده و رنگین کمان زیبایی در آسمان ظاهر شد 1.0\n",
      "متاسفانه ولی کلید نبود 1.0\n"
     ]
    }
   ],
   "source": [
    "print('متن اول:' + text1)\n",
    "print('متن دوم:' + text2)\n",
    "print(\"جملات مشابه: \")\n",
    "for i, x in enumerate(most_sim):\n",
    "    if sim_arr[x][i] > .5 :\n",
    "        print(text1_list_word[x].replace('\\n','') + ' ' + str(sim_arr[x][i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
